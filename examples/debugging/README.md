# Debugging

This example shows how to run the [Titanic example](../titanic/README.md) locally to debug your code.

- [Debugging](#debugging)
  - [Debug using only local assets](#debug-using-only-local-assets)
    - [Prerequisites](#prerequisites)
    - [Data and script preparation](#data-and-script-preparation)
    - [Run and debug our pipeline](#run-and-debug-our-pipeline)
    - [Difference with the Titanic example](#difference-with-the-titanic-example)
  - [Debug locally using the Titanic example assets](#debug-locally-using-the-titanic-example-assets)
    - [Create new assets](#create-new-assets)
    - [Use a dataset from the deployed platform](#use-a-dataset-from-the-deployed-platform)

## Debug using only local assets

### Prerequisites

In order to run this example, you'll need to:

* use Python 3
* have [Docker](https://www.docker.com/) installed
* [install `substra`](../../README.md#install)
* checkout this repository

All commands in this example are run from the `substra/examples/debugging/` folder.

### Data and script preparation

Follow the [data preparation phase](../titanic/README.md#data-preparation) instructions from the Titanic example.

The objective, data manager and algorithms that we use are defined in the Titanic example.

### Run and debug our pipeline

The [local_debugging.py](./scripts/local_debugging.py) contains the code to add the assets to the platform,
train the algorithm and make predictions.

In case the script is run on the 'remote' backend, the displayed performance is zero since the script ends
before the asynchronous execution.

### Difference with the Titanic example

The differences with the Titanic example (executed on a running Substra platform) are:
- the client is given the argument `debug=True` and there is no need of a username and password
- Adding the dataset and algorithm must be done in the same script since the objects (traintuple, objective...) are saved in memory and erased at the end of the script

Apart from this, this example is the same as the Titanic example.

## Debug locally using the Titanic example assets

You can also use your own traintuple and testtuple with the dataset, objective and algo from the Titanic example.

For this, run the [Titanic example](../titanic/README.md) and keep the Substra platform running. You will need
the `assets_keys.json` generated while running the Titanic example.

The [`hybrid_debugging.py`](./scripts/hybrid_debugging.py) script contains the code to load the 
Titanic asset keys then create a traintuple and testtuple using those.
In this setup, you can also create any asset you want, as in the example with only local assets.

### Create new assets

With `debug=True` in the client, the deployed Substra platform is **read-only**: all new assets are created locally.

### Use a dataset from the deployed platform

The data cannot leave the deployed platform. When a traintuple or testtuple uses a dataset from the remote platform,
it runs on the fake data that the dataset opener generates (see the `fake_X` and `fake_y` methods in the 
[dataset opener](../titanic/assets/dataset/opener.py)). The number of samples generated by the `fake` methods is equal to the number
of data samples that the traintuple or testtuple uses.

In the Titanic example, there are 10 data samples, so the traintuple we create in the script uses 10 samples:

```python
traintuple = client.add_traintuple(
    {
        ...
        "train_data_sample_keys": assets_keys["train_data_sample_keys"],
    },
    exist_ok=True,
)
```

So in this mode the traintuple runs on 10 fake data samples generated by the opener.

