# Local debugging

- [Local debugging](#local-debugging)
  - [Prerequisites](#prerequisites)
  - [Data and script preparation](#data-and-script-preparation)
  - [Run and debug our pipeline](#run-and-debug-our-pipeline)
  - [Difference with the Titanic example](#difference-with-the-titanic-example)
- [Hybrid debugging](#hybrid-debugging)

This example shows how to run the [Titanic example](../titanic/README.md) locally to debug your code.  
There are two possibilities as to which data to use for debugging:
* if you have data samples available on disk: use those
* if you don't: use random data generated on the fly by the opener from the Titanic example

## Prerequisites

In order to run this example, you'll need to:

* use Python 3
* have [Docker](https://www.docker.com/) installed
* [install `substra`](../../README.md#install)
* checkout this repository

All commands in this example are run from the `substra/examples/local_debugging/` folder.

## Data and script preparation

Follow the [data preparation phase](../titanic/README.md#data-preparation) instructions from the Titanic example.

The objective, data manager and algorithms that we use are defined in the Titanic example.

## Run and debug our pipeline

The [local_debugging.py](./scripts/local_debugging.py) script contains the code to add the assets to the platform, 
train the algorithm and make predictions.

In case the script is run on the 'remote' backend, the displayed performance is zero since the script ends 
before the asynchronous execution.

## Difference with the Titanic example

The differences with the Titanic example (executed on a running Substra platform) are:
- the client is given the argument `backend="local"` and there is no need of a username and password
- Adding the dataset and algorithm must be done in the same script since the objects (traintuple, objective...) are saved in memory and erased at the end of the script

Apart from this, this example is the same as the Titanic example.

# Hybrid debugging

The hybrid debugging consists in testing an algorithm locally on the fake data generated by a dataset on the deployed Substra platform.

To do this,
1. download the dataset (opener and description),
2. add it to the local client
3. write your code as with the local debugging with a few exceptions:
    * since the algorithm runs on fake data, there are no train_data_samples nor test_data_samples
    * set `fake_data` to `True` when adding the traintuple
    * set `fake_data` to `True` when adding the testtuple

Use the `n_fake_samples` argument to get a specific number of fake samples from the dataset.

The [hybrid_debugging.py](./scripts/hybrid_debugging.py) script contains the code to add the assets to the platform,
train the algorithm and make predictions.

